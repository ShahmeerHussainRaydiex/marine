{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings \n",
    "import sys\n",
    "import importlib\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "directory = Path(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "sys.path.append(str(directory))\n",
    "\n",
    "modules_to_reload = [\n",
    "    'src.metric_util_OLD'\n",
    "]\n",
    "\n",
    "# Reload and import each module\n",
    "for module_name in modules_to_reload:\n",
    "    module = importlib.import_module(module_name)\n",
    "    importlib.reload(module)\n",
    "    globals().update({name: getattr(module, name) for name in dir(module) if not name.startswith('_')})\n",
    "\n",
    "from src.metric_util_OLD import *\n",
    "\n",
    "from src.config.landobject_config import north_sea_ports\n",
    " \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/Users/loucas/Documents/ORG/things too big for git/seabed_substrate.geojson'\n",
    "\n",
    "# Load the AOI\n",
    "seabed = gpd.read_file(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n",
      "Unclassified lithology: n/a\n"
     ]
    }
   ],
   "source": [
    "def classify_substrate(gdf):\n",
    "    # Define substrate categories\n",
    "    substrate_categories = {\n",
    "        'Rocky or till': ['rock', 'igneous rock', 'metamorphic rock', 'granite', 'basalt', 'gneiss', 'schist', 'quartzite', 'till',\n",
    "                          'andesite', 'peridotite', 'phonolite',  'dacite', 'granitoid', 'quartz diorite', 'diorite', 'tuffite', 'gabbro', 'igneous material',\n",
    "                          'wacke', 'ash tuff, lapillistone, and lapilli tuff'],  # Added wacke here as it's typically a hard sandstone\n",
    "        'Mud to muddy Sand': ['clay', 'mud', 'mudstone', 'silt', 'silty sand', 'sandy mud', 'slate', 'shale', 'limestone', 'chalk', 'calcareous carbonate sediment', 'calcareous carbonate sedimentary material'],\n",
    "        'Sand': ['sand', 'sandstone', 'quartz sand', 'dolomite'],\n",
    "        'Coarse substrate': ['gravel', 'pebbles', 'cobbles', 'boulders', 'conglomerate'],\n",
    "        'Mixed sediment': ['mixed sediment', 'sand and gravel', 'muddy gravel', 'sedimentary material'],\n",
    "        # 'Calcareous sediment': ['limestone', 'chalk', 'calcareous carbonate sediment', 'calcareous carbonate sedimentary material']\n",
    "    }\n",
    "    \n",
    "    def get_substrate(lithology):\n",
    "        if pd.isna(lithology) or lithology == 'NULL':\n",
    "            return 'Unknown'\n",
    "        \n",
    "        lithology = str(lithology).lower()\n",
    "        \n",
    "        for category, materials in substrate_categories.items():\n",
    "            if any(material in lithology for material in materials):\n",
    "                return category\n",
    "        \n",
    "        print(f\"Unclassified lithology: {lithology}\")\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Apply the function to create a new 'Substrate' column\n",
    "    gdf['Substrate'] = gdf['LithologyValue1'].apply(get_substrate)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "# Example usage:\n",
    "gdf = classify_substrate(seabed)\n",
    "# Dissolve the GeoDataFrame by 'Hardness'\n",
    "dissolved_gdf = gdf.dissolve(by='Substrate', aggfunc='first')\n",
    "\n",
    "# Reset the index to make 'Hardness' a column again\n",
    "dissolved_gdf = dissolved_gdf.reset_index()\n",
    "\n",
    "gdf_reprojected = dissolved_gdf.to_crs(epsg=3035)\n",
    "\n",
    "# Save the dissolved GeoDataFrame to a new GeoJSON file\n",
    "gdf_reprojected.to_file('/Users/loucas/Documents/ORG/things too big for git/seabed_substrate_final.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio import features\n",
    "\n",
    "def create_point_count_raster(gdf, template_raster_path, output_raster_path):\n",
    "    # Read the template raster\n",
    "    with rasterio.open(template_raster_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        transform = src.transform\n",
    "        shape = src.shape\n",
    "\n",
    "    # Update metadata for the new raster\n",
    "    meta.update(dtype=rasterio.uint32, count=1, nodata=None)\n",
    "\n",
    "    # Create a numpy array to store the point counts\n",
    "    point_count = np.zeros(shape, dtype=np.uint32)\n",
    "\n",
    "    # Rasterize the points, counting them for each cell\n",
    "    shapes = ((geom, 1) for geom in gdf.geometry)\n",
    "    burned = features.rasterize(shapes=shapes, out=point_count, transform=transform, \n",
    "                                all_touched=False, merge_alg=rasterio.enums.MergeAlg.add)\n",
    "\n",
    "    # Write the new raster\n",
    "    with rasterio.open(output_raster_path, 'w', **meta) as dst:\n",
    "        dst.write(burned, 1)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "bird_fp = '/Users/loucas/Downloads/birds.geojson'\n",
    "template_raster_fp = '/Users/loucas/Documents/ORG/github/marine-planning/data/rasters/international/wind_speed.tif'\n",
    "output_raster_path = '/Users/loucas/Downloads/birds.tiff'\n",
    "\n",
    "\n",
    "gdf = gpd.read_file(bird_fp)\n",
    "\n",
    "create_point_count_raster(gdf, template_raster_fp, output_raster_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hub generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import math\n",
    "\n",
    "def generate_hub_configurations(hubs, max_distance_km=20, iterations=1000):\n",
    "    def modify_coordinate(coord, max_distance_km):\n",
    "        # Convert max_distance from km to degrees (approximate)\n",
    "        max_distance_deg = max_distance_km / 111  # 1 degree is approximately 111 km\n",
    "        return coord + random.uniform(-max_distance_deg, max_distance_deg)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        new_hubs = copy.deepcopy(hubs)\n",
    "        for hub in new_hubs.values():\n",
    "            hub['latitude'] = modify_coordinate(hub['latitude'], max_distance_km)\n",
    "            hub['longitude'] = modify_coordinate(hub['longitude'], max_distance_km)\n",
    "        yield new_hubs\n",
    "\n",
    "# Example usage:\n",
    "hubs = {\n",
    "    \"sorlige nordsjo 2\": {\"latitude\": 57.853, \"longitude\": 4.748, \"capacity\": 3},\n",
    "    \"danish\": {\"latitude\": 56.089, \"longitude\": 5.664, \"capacity\": 10},\n",
    "    \"german\": {\"latitude\": 54.971, \"longitude\": 6.264, \"capacity\": 10},\n",
    "    \"NL\": {\"latitude\": 54.122, \"longitude\": 3.905, \"capacity\": 10},\n",
    "    \"PE zone\": {\"latitude\": 51.550, \"longitude\": 2.470, \"capacity\": 3.5},\n",
    "}\n",
    "\n",
    "generator = generate_hub_configurations(hubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_all_hub_configurations(hubs, distance_km=20):\n",
    "    # Convert 20 km to degrees (approximate)\n",
    "    distance_deg = distance_km / 111  # 1 degree is approximately 111 km\n",
    "\n",
    "    # Generate the 5 possible locations for each hub\n",
    "    hub_locations = {}\n",
    "    for hub_name, hub_data in hubs.items():\n",
    "        base_lat, base_lon = hub_data['latitude'], hub_data['longitude']\n",
    "        hub_locations[hub_name] = [\n",
    "            (base_lat, base_lon),  # Current\n",
    "            (base_lat + distance_deg, base_lon),  # North\n",
    "            (base_lat, base_lon + distance_deg),  # East\n",
    "            (base_lat, base_lon - distance_deg),  # West\n",
    "            (base_lat - distance_deg, base_lon),  # South\n",
    "        ]\n",
    "\n",
    "    # Generate all possible combinations\n",
    "    hub_names = list(hubs.keys())\n",
    "    location_combinations = itertools.product(range(5), repeat=len(hub_names))\n",
    "\n",
    "    for combo in location_combinations:\n",
    "        new_hubs = copy.deepcopy(hubs)\n",
    "        for hub_name, location_index in zip(hub_names, combo):\n",
    "            new_lat, new_lon = hub_locations[hub_name][location_index]\n",
    "            new_hubs[hub_name]['latitude'] = new_lat\n",
    "            new_hubs[hub_name]['longitude'] = new_lon\n",
    "        yield new_hubs\n",
    "\n",
    "# Example usage:\n",
    "hubs = {\n",
    "    \"sorlige nordsjo 2\": {\"latitude\": 57.853, \"longitude\": 4.748, \"capacity\": 3},\n",
    "    \"danish\": {\"latitude\": 56.089, \"longitude\": 5.664, \"capacity\": 10},\n",
    "    \"german\": {\"latitude\": 54.971, \"longitude\": 6.264, \"capacity\": 10},\n",
    "    \"NL\": {\"latitude\": 54.122, \"longitude\": 3.905, \"capacity\": 10},\n",
    "    \"PE zone\": {\"latitude\": 51.550, \"longitude\": 2.470, \"capacity\": 3.5},\n",
    "}\n",
    "\n",
    "generator = generate_all_hub_configurations(hubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "def create_grid_gdf(raster_path):\n",
    "    # Open the raster file\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Get raster bounds and resolution\n",
    "        left, bottom, right, top = src.bounds\n",
    "        res_x, res_y = src.res\n",
    "\n",
    "    # Create vertical lines\n",
    "    vertical_lines = []\n",
    "    x = left\n",
    "    while x <= right:\n",
    "        line = LineString([(x, bottom), (x, top)])\n",
    "        vertical_lines.append(line)\n",
    "        x += res_x\n",
    "\n",
    "    # Create horizontal lines\n",
    "    horizontal_lines = []\n",
    "    y = bottom\n",
    "    while y <= top:\n",
    "        line = LineString([(left, y), (right, y)])\n",
    "        horizontal_lines.append(line)\n",
    "        y += res_y\n",
    "\n",
    "    # Combine all lines\n",
    "    all_lines = vertical_lines + horizontal_lines\n",
    "\n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(geometry=all_lines, crs=src.crs)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "# Usage\n",
    "raster_path = '/Users/loucas/Downloads/big.tif'\n",
    "grid_gdf = create_grid_gdf(raster_path)\n",
    "\n",
    "# Save the grid as a shapefile or geopackage\n",
    "grid_gdf.to_file('/Users/loucas/Documents/ORG/things too big for git/grid.geojson', driver='GeoJSON')  # or use .gpkg for geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gdf(north_sea_ports):\n",
    "    # List to hold the data for non-substation locations\n",
    "    non_substations = []\n",
    "\n",
    "    # Loop through each country in the data\n",
    "    for country, locations in north_sea_ports.items():\n",
    "        # Loop through each location\n",
    "        for location_name, location_data in locations.items():\n",
    "            if location_data['designation'] != 'substation':\n",
    "                # Create a dictionary with relevant data\n",
    "                non_substations.append({\n",
    "                    'location': location_name,\n",
    "                    'latitude': location_data['latitude'],\n",
    "                    'longitude': location_data['longitude'],\n",
    "                    'designation': location_data['designation'],\n",
    "                    'country': location_data['country'],\n",
    "                    'geometry': Point(location_data['longitude'], location_data['latitude'])\n",
    "                })\n",
    "\n",
    "    # Convert list of non-substation locations to a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(non_substations, geometry='geometry', crs='EPSG:4326')\n",
    "    # Conver to EPSG:3035\n",
    "    gdf = gdf.to_crs(epsg=3035)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "# Example usage:\n",
    "gdf = convert_to_gdf(north_sea_ports)\n",
    "\n",
    "# Save the GeoDataFrame to a shapefile or geopackage\n",
    "gdf.to_file('/Users/loucas/Documents/ORG/things too big for git/ports.geojson', driver='GeoJSON')  # or use .gpkg for geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/loucas/Downloads/iho/iho.shp'\n",
    "\n",
    "gdf = gpd.read_file(file)\n",
    "# convert to 3035\n",
    "gdf = gdf.to_crs(epsg=3035)\n",
    "gdf.to_file('/Users/loucas/Documents/ORG/things too big for git/NorthSea.geojson', driver='GeoJSON')  # or use .gpkg for geopackage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
