{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.enums import Resampling\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "directory = Path(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "sys.path.append(str(directory))\n",
    "\n",
    "mammal_path = os.path.join(directory, 'ecoimpactmapper/ecocomponents/mammals')\n",
    "invertebrate_path = os.path.join(directory, 'ecoimpactmapper/ecocomponents/invertebrates')\n",
    "fish_path = os.path.join(directory, 'ecoimpactmapper/ecocomponents/fish') # Not yet implemented\n",
    "bird_path = os.path.join(directory, 'ecoimpactmapper/ecocomponents/birds') # Not yet implemented\n",
    "\n",
    "aoi_path = os.path.join(directory, 'data', 'vectors', 'international', 'aoi.geojson')\n",
    "aoi = gpd.read_file(aoi_path)\n",
    "aoi = aoi.to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tif_from_gdf(gdf, output_tif, value_column='Overall Probability', cell_size_x=0.5, cell_size_y=0.5):\n",
    "    # Get bounds from the GeoDataFrame\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    \n",
    "    # Set resolution based on the desired cell size\n",
    "    xres = cell_size_x\n",
    "    yres = cell_size_y\n",
    "\n",
    "    # Create an empty raster array\n",
    "    num_cols = int((maxx - minx) / xres) + 1\n",
    "    num_rows = int((maxy - miny) / yres) + 1\n",
    "    raster = np.zeros((num_rows, num_cols), dtype=np.float32)\n",
    "\n",
    "    # Map the points to the raster grid\n",
    "    for _, row in gdf.iterrows():\n",
    "        col = int((row.geometry.x - minx) / xres)\n",
    "        row_idx = int((maxy - row.geometry.y) / yres)\n",
    "        raster[row_idx, col] = row[value_column]\n",
    "\n",
    "    # Define the affine transform\n",
    "    transform = from_origin(minx, maxy, xres, yres)\n",
    "\n",
    "    # Create and save the raster file\n",
    "    with rasterio.open(\n",
    "        output_tif,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=raster.shape[0],\n",
    "        width=raster.shape[1],\n",
    "        count=1,\n",
    "        dtype=raster.dtype,\n",
    "        crs=gdf.crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "    return chardet.detect(raw_data)['encoding']\n",
    "\n",
    "\n",
    "def load_csvs_into_dict(root_folder):\n",
    "    dataframes_dict = {}\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and file != 'template_df.csv':\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, skiprows=6, header=1, encoding='ISO-8859-1')\n",
    "                    dataframes_dict[file] = df\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file}: {str(e)}\")\n",
    "    \n",
    "    return dataframes_dict\n",
    "\n",
    "\n",
    "def convert_to_geodataframe(dataframes_dict, aoi, clip = True):\n",
    "    gdfs_dict = {}\n",
    "    \n",
    "    for file_name, df in dataframes_dict.items():\n",
    "        try:\n",
    "            geometry = [Point(xy) for xy in zip(df['Center Long'], df['Center Lat'])]\n",
    "            gdf = gpd.GeoDataFrame(df, crs=\"EPSG:4326\", geometry=geometry)\n",
    "\n",
    "            # Clip to the AOI\n",
    "            gdf = gpd.clip(gdf, aoi) if clip else gdf\n",
    "            \n",
    "            \n",
    "            gdfs_dict[file_name.split('.')[0]] = gdf\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {file_name} to GeoDataFrame: {str(e)}\")\n",
    "    \n",
    "    return gdfs_dict\n",
    "\n",
    "\n",
    "def overlay_points_on_raster(input_tif, gdf, output_tif):\n",
    "    # Read the existing raster\n",
    "    with rasterio.open(input_tif) as src:\n",
    "        raster_data = src.read(1)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "        bounds = src.bounds\n",
    "\n",
    "    # Create an empty raster array for the output\n",
    "    new_raster_data = np.zeros_like(raster_data, dtype=np.uint8)\n",
    "\n",
    "    # Map the points to the raster grid\n",
    "    for _, row in gdf.iterrows():\n",
    "        # Get the x and y coordinates of the point\n",
    "        x, y = row.geometry.x, row.geometry.y\n",
    "\n",
    "        # Convert the coordinates to column and row indices in the raster\n",
    "        col, row_idx = ~transform * (x, y)\n",
    "        col, row_idx = int(col), int(row_idx)\n",
    "\n",
    "        # Ensure the indices are within the raster bounds\n",
    "        if 0 <= col < width and 0 <= row_idx < height:\n",
    "            new_raster_data[row_idx, col] = 1\n",
    "\n",
    "    # Save the new raster\n",
    "    with rasterio.open(\n",
    "        output_tif,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=new_raster_data.dtype,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(new_raster_data, 1)\n",
    "\n",
    "\n",
    "def sum_rasters_in_folder(folder_path, output_tif):\n",
    "    # Get a list of all raster files in the folder\n",
    "    raster_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "\n",
    "    if not raster_files:\n",
    "        raise ValueError(\"No raster files found in the specified folder.\")\n",
    "\n",
    "    # Read the first raster to get metadata\n",
    "    with rasterio.open(raster_files[0]) as src:\n",
    "        profile = src.profile\n",
    "        data_sum = np.zeros((src.height, src.width), dtype=np.float32)\n",
    "\n",
    "    # Sum all rasters\n",
    "    for raster_file in raster_files:\n",
    "        with rasterio.open(raster_file) as src:\n",
    "            data = src.read(1)\n",
    "            data_sum += data\n",
    "\n",
    "    # Update the profile to reflect the number of layers in the output raster\n",
    "    profile.update(dtype=rasterio.float32, count=1)\n",
    "\n",
    "    # Save the sum raster\n",
    "    with rasterio.open(output_tif, 'w', **profile) as dst:\n",
    "        dst.write(data_sum, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropoda.csv\n",
      "cnidaria.csv\n",
      "echinodermata.csv\n",
      "mollusca.csv\n"
     ]
    }
   ],
   "source": [
    "# Invertebrates\n",
    "\n",
    "raster_folder = os.path.join(invertebrate_path, 'rasters')\n",
    "\n",
    "if not os.path.exists(raster_folder):\n",
    "    os.makedirs(raster_folder)\n",
    "\n",
    "# loop through the files in the folder\n",
    "for file in os.listdir(invertebrate_path):\n",
    "\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    print(file)\n",
    "    file_path = os.path.join(invertebrate_path, file)\n",
    "    template_df = pd.read_csv(file_path, header=3, encoding='ISO-8859-1')\n",
    "    geometry = [Point(xy) for xy in zip(template_df['Center Longitude'], template_df['Center Latitude'])]\n",
    "    template_gdf = gpd.GeoDataFrame(template_df, crs=\"EPSG:4326\", geometry=geometry)\n",
    "\n",
    "    template_gdf = gpd.clip(template_gdf, aoi)\n",
    "\n",
    "    output_tif = os.path.join(raster_folder, f\"{os.path.splitext(file)[0]}.tif\")\n",
    "    create_tif_from_gdf(template_gdf, output_tif, value_column='Species Count', cell_size_x=0.5, cell_size_y=0.5)\n",
    "\n",
    "\n",
    "sum_rasters_in_folder(raster_folder, os.path.join(raster_folder, 'invertebrates_sum.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mammals\n",
    "\n",
    "raster_folder = os.path.join(mammal_path, 'rasters')\n",
    "template_raster = os.path.join(raster_folder, 'template_raster.tif')\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(raster_folder):\n",
    "    os.makedirs(raster_folder)\n",
    "\n",
    "# Create the template raster\n",
    "template_csv = os.path.join(mammal_path, 'template_df.csv')\n",
    "\n",
    "template_df = pd.read_csv(template_csv, header=8, encoding='ISO-8859-1')\n",
    "geometry = [Point(xy) for xy in zip(template_df['Center Long'], template_df['Center Lat'])]\n",
    "template_gdf = gpd.GeoDataFrame(template_df, crs=\"EPSG:4326\", geometry=geometry)\n",
    "\n",
    "template_gdf = gpd.clip(template_gdf, aoi)\n",
    "\n",
    "create_tif_from_gdf(template_gdf, template_raster, value_column='Overall Probability')\n",
    "\n",
    "\n",
    "# loop through the files in the folder\n",
    "df_dict = load_csvs_into_dict(mammal_path)\n",
    "gdf_dict = convert_to_geodataframe(df_dict, aoi)\n",
    "\n",
    "for file_name, gdf in gdf_dict.items():\n",
    "    output_tif = f'/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/mammals/rasters/{file_name}.tif'\n",
    "    overlay_points_on_raster(template_raster, gdf, output_tif)\n",
    "\n",
    "sum_rasters_in_folder(raster_folder, os.path.join(mammal_path, 'mammals_sum.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NOCN/lib/python3.9/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "/var/folders/mk/ks8rs6mx6_30xy34h6hr7cs00000gn/T/ipykernel_62121/3741913678.py:11: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  fish_gdf = fish_gdf[fish_gdf.geometry.area != fish_gdf.geometry.area.max()]\n"
     ]
    }
   ],
   "source": [
    "## FISH FROM REDLIST\n",
    "\n",
    "fish_path = '/Users/loucas/Downloads/redlist_species_data_1ed23a96-60e2-40dd-b5f3-003ef20493f0/data_0.shp'\n",
    "\n",
    "fish_gdf = gpd.read_file(fish_path)\n",
    "\n",
    "# clip to aoi\n",
    "fish_gdf = gpd.clip(fish_gdf, aoi)\n",
    "\n",
    "# remove the largest polygon as it is just the aoi for some reason\n",
    "fish_gdf = fish_gdf[fish_gdf.geometry.area != fish_gdf.geometry.area.max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your GeoDataFrame is called 'gdf'\n",
    "# and you have a path to your template raster\n",
    "\n",
    "# Step 1: Open the template raster\n",
    "with rasterio.open('/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/mammals/mammals_sum.tif') as src:\n",
    "    template_meta = src.meta.copy()\n",
    "    template_transform = src.transform\n",
    "    template_crs = src.crs\n",
    "    template_shape = src.shape\n",
    "\n",
    "# Step 2: Create an empty raster with the same properties as the template\n",
    "raster = np.zeros(template_shape, dtype=np.int32)\n",
    "\n",
    "# Step 3: Prepare shapes for rasterization\n",
    "shapes = ((geom, 1) for geom in fish_gdf.geometry)\n",
    "\n",
    "# Step 4: Rasterize the polygons, counting each polygon once per cell\n",
    "rasterized = features.rasterize(\n",
    "    shapes=shapes,\n",
    "    out=raster,\n",
    "    transform=template_transform,\n",
    "    all_touched=False,  # Changed to False\n",
    "    merge_alg=rasterio.enums.MergeAlg.add\n",
    ")\n",
    "\n",
    "# Step 5: Clip the values to the maximum number of polygons\n",
    "max_polygons = len(fish_gdf)\n",
    "rasterized = np.clip(rasterized, 0, max_polygons)\n",
    "\n",
    "# Step 6: Save the raster to a file\n",
    "output_meta = template_meta.copy()\n",
    "output_meta.update({\n",
    "    'dtype': 'int32',\n",
    "    'count': 1\n",
    "})\n",
    "\n",
    "with rasterio.open('/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/fish.tif', 'w', **output_meta) as dst:\n",
    "    dst.write(raster, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/phytoplankton.tif -> /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/normalized_phytoplankton_3035.tif\n",
      "Processed /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/fish.tif -> /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/normalized_fish_3035.tif\n",
      "Processed /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/invertebrates_sum.tif -> /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/normalized_invertebrates_sum_3035.tif\n",
      "Processed /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/mammals_sum.tif -> /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/normalized_mammals_sum_3035.tif\n",
      "Processed /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/birds.tif -> /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test/normalized_birds_3035.tif\n"
     ]
    }
   ],
   "source": [
    "# Convert all tifs to 3035 and normalize between 0 and 1\n",
    "\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "import numpy as np\n",
    "\n",
    "def normalize_and_reproject(input_file, output_file):\n",
    "    # Open the input file\n",
    "    ds = gdal.Open(input_file)\n",
    "    \n",
    "    # Read the data as a NumPy array\n",
    "    data = ds.ReadAsArray().astype(np.float32)\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    data = np.nan_to_num(data, nan=0.0)\n",
    "    \n",
    "    # Normalize the data between 0 and 1\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    if min_val != max_val:\n",
    "        normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_data = data  # Avoid division by zero if all values are the same\n",
    "    \n",
    "    # Get the geotransform and projection of the input file\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "    \n",
    "    # Check if the input file has a defined CRS\n",
    "    if not projection:\n",
    "        # If no CRS is defined, set it to EPSG:4326 (WGS84)\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromEPSG(4326)\n",
    "        projection = srs.ExportToWkt()\n",
    "        print(f\"No CRS found for {input_file}. Setting to EPSG:4326.\")\n",
    "    \n",
    "    # Create the output dataset\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_ds = driver.Create(output_file, ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    out_ds.SetGeoTransform(geotransform)\n",
    "    out_ds.SetProjection(projection)\n",
    "    \n",
    "    # Write the normalized data to the output file\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(normalized_data)\n",
    "    \n",
    "    # Close the datasets\n",
    "    ds = None\n",
    "    out_ds = None\n",
    "    \n",
    "    # Reproject to EPSG:3035\n",
    "    output_3035 = output_file.replace('.tif', '_3035.tif')\n",
    "    gdal.Warp(output_3035, output_file, dstSRS='EPSG:3035')\n",
    "    \n",
    "    # Remove the intermediate file\n",
    "    os.remove(output_file)\n",
    "    \n",
    "    print(f\"Processed {input_file} -> {output_3035}\")\n",
    "\n",
    "def process_folder(input_folder):\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.tif'):\n",
    "            input_file = os.path.join(input_folder, filename)\n",
    "            output_file = os.path.join(input_folder, f'normalized_{filename}')\n",
    "            normalize_and_reproject(input_file, output_file)\n",
    "\n",
    "\n",
    "input_folder = '/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test'\n",
    "process_folder(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS STUFF IS FOR GETTING THE COMPONENT DATA INTO THE CSV FOR THE ECOIMPACT MAPPER FORMAT\n",
    "\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def generate_ecoimpact_map(shape, num_clusters=10, cluster_size=20, smoothness=8):\n",
    "    # Your existing function code here\n",
    "    map_array = np.zeros(shape)\n",
    "    \n",
    "    for _ in range(num_clusters):\n",
    "        center = tuple(np.random.randint(0, dim) for dim in shape)\n",
    "        value = np.random.uniform(2.0, 5.0)\n",
    "        \n",
    "        for i in range(-cluster_size, cluster_size + 1):\n",
    "            for j in range(-cluster_size, cluster_size + 1):\n",
    "                x = (center[0] + i) % shape[0]\n",
    "                y = (center[1] + j) % shape[1]\n",
    "                map_array[x, y] = value\n",
    "    \n",
    "    smoothed_map = gaussian_filter(map_array, sigma=smoothness)\n",
    "    smoothed_map = (smoothed_map - smoothed_map.min()) / (smoothed_map.max() - smoothed_map.min()) * 3 + 2\n",
    "    return np.round(smoothed_map, decimals=2)\n",
    "\n",
    "\n",
    "def folder_tifs_to_dataframe(folder_path):\n",
    "    tif_files = [f for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "    if not tif_files:\n",
    "        raise ValueError(\"No TIF files found in the specified folder.\")\n",
    "\n",
    "    dataframes = []\n",
    "    \n",
    "    for tif_file in tif_files:\n",
    "        tif_path = os.path.join(folder_path, tif_file)\n",
    "        base_name = os.path.splitext(tif_file)[0]\n",
    "        column_name = base_name\n",
    "        stressor_column_name = f\"{base_name}_stressor\"\n",
    "        \n",
    "        with rasterio.open(tif_path) as src:\n",
    "            raster_data = src.read(1)\n",
    "            transform = src.transform\n",
    "            \n",
    "            # Generate stressor map\n",
    "            stressor_data = generate_ecoimpact_map(raster_data.shape)\n",
    "\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "        values = []\n",
    "        stressor_values = []\n",
    "\n",
    "        rows, cols = raster_data.shape\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                x, y = rasterio.transform.xy(transform, row + 0.5, col + 0.5)\n",
    "                value = raster_data[row, col]\n",
    "                stressor_value = stressor_data[row, col]\n",
    "                \n",
    "                x_coords.append(x)\n",
    "                y_coords.append(y)\n",
    "                values.append(value)\n",
    "                stressor_values.append(stressor_value)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'X': x_coords,\n",
    "            'Y': y_coords,\n",
    "            column_name: values,\n",
    "            #stressor_column_name: stressor_values\n",
    "        })\n",
    "        \n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Merge all dataframes\n",
    "    result_df = dataframes[0]\n",
    "    for df in dataframes[1:]:\n",
    "        result_df = pd.merge(result_df, df, on=['X', 'Y'])\n",
    "\n",
    "    return result_df\n",
    "\n",
    "tif_path = '/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test'\n",
    "\n",
    "\n",
    "df = folder_tifs_to_dataframe(tif_path)\n",
    "\n",
    "df.to_csv('/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted eco_sens_wind.txt to eco_sens_wind.tif\n",
      "Converted eco_sens_aquaculture.txt to eco_sens_aquaculture.tif\n",
      "Converted eco_sens_fpv.txt to eco_sens_fpv.tif\n"
     ]
    }
   ],
   "source": [
    "## CONVERT THE RESULTING ECO SENSITIVITY MAPS TO TIF\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "def convert_txt_to_tif(input_file, output_file, cell_size=5000):\n",
    "    # Read data from txt file\n",
    "    with open(input_file, 'r') as f:\n",
    "        next(f)  # Skip the header line\n",
    "        data = [line.strip().split(',') for line in f]  # Assuming comma-separated values\n",
    "    \n",
    "    x = np.array([float(row[0]) for row in data])\n",
    "    y = np.array([float(row[1]) for row in data])\n",
    "    values = np.array([float(row[2]) for row in data])\n",
    "\n",
    "    # Determine raster properties\n",
    "    # Adjust x_min and y_min to represent the top-left corner of the raster\n",
    "    x_min, x_max = x.min() - cell_size, x.max()\n",
    "    y_min, y_max = y.min(), y.max() + cell_size\n",
    "    \n",
    "    # Calculate width and height, adding 1 to include the rightmost and topmost cells\n",
    "    width = int(np.ceil((x_max - x_min) / cell_size))\n",
    "    height = int(np.ceil((y_max - y_min) / cell_size))\n",
    "\n",
    "    # Create an empty raster\n",
    "    raster = np.full((height, width), np.nan, dtype=np.float32)\n",
    "\n",
    "    # Fill the raster with values\n",
    "    # Adjust the indices calculation to account for bottom-right corner coordinates\n",
    "    col_indices = np.clip(((x - x_min) / cell_size - 1).astype(int), 0, width - 1)\n",
    "    row_indices = np.clip((height - 1 - (y - y_min) / cell_size).astype(int), 0, height - 1)\n",
    "    raster[row_indices, col_indices] = values\n",
    "\n",
    "    # Create the GeoTIFF\n",
    "    # Use x_min and y_max for the origin as they now represent the top-left corner\n",
    "    transform = from_origin(x_min, y_max, cell_size, cell_size)\n",
    "    with rasterio.open(\n",
    "        output_file,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=raster.dtype,\n",
    "        crs='EPSG:3035',\n",
    "        transform=transform,\n",
    "        nodata=np.nan\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "\n",
    "\n",
    "# Directory containing the txt files\n",
    "input_dir = '/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/ecocomponents/monopile'\n",
    "\n",
    "# Process all txt files in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        input_file = os.path.join(input_dir, filename)\n",
    "        output_file = os.path.join(input_dir, filename.replace('.txt', '.tif'))\n",
    "        convert_txt_to_tif(input_file, output_file)\n",
    "        print(f'Converted {filename} to {filename.replace(\".txt\", \".tif\")}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
