{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "\n",
    "fishing_hours_path = '/Users/loucas/Documents/ORG/things too big for git/fishing_hours.csv'\n",
    "trawling_path = '/Users/loucas/Documents/ORG/things too big for git/surface_subsurface.csv'\n",
    "squares_path = '/Users/loucas/Documents/ORG/things too big for git/squares.geojson'\n",
    "\n",
    "fishing_hours = pd.read_csv(fishing_hours_path)\n",
    "trawling = pd.read_csv(trawling_path)\n",
    "squares = gpd.read_file(squares_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "def check_column_values(df1, df2, column_name):\n",
    "    # Check if the column exists in both DataFrames\n",
    "    if column_name not in df1.columns or column_name not in df2.columns:\n",
    "        return None, f\"Column '{column_name}' not found in one or both DataFrames\"\n",
    "    \n",
    "    # Get the unique values from both DataFrames\n",
    "    df1_values = set(df1[column_name].unique())\n",
    "    df2_values = set(df2[column_name].unique())\n",
    "    \n",
    "    # Find values in df1 that are not in df2\n",
    "    missing_values = list(df1_values - df2_values)\n",
    "    print(len(missing_values))\n",
    "\n",
    "\n",
    "check_column_values(squares, fishing_hours, 'c_squar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 84 rows in df1 did not find a match in df2.\n",
      "Warning: 6116 rows in df1 did not find a match in df2.\n",
      "Warning: 5655 rows in df1 did not find a match in df2.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_column_from_df2_to_df1(df1, df2, match_column, new_column):\n",
    "    # Check if the columns exist in the respective DataFrames\n",
    "    if match_column not in df1.columns or match_column not in df2.columns:\n",
    "        return None, f\"Match column '{match_column}' not found in one or both DataFrames\"\n",
    "    if new_column not in df2.columns:\n",
    "        return None, f\"New column '{new_column}' not found in the second DataFrame\"\n",
    "    \n",
    "    # Perform a left merge\n",
    "    merged_df = df1.merge(df2[[match_column, new_column]], \n",
    "                          on=match_column, \n",
    "                          how='left')\n",
    "    \n",
    "    # Check for any rows that didn't find a match\n",
    "    unmatched = merged_df[merged_df[new_column].isna()]\n",
    "    \n",
    "    if not unmatched.empty:\n",
    "        print(f\"Warning: {len(unmatched)} rows in df1 did not find a match in df2.\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "merged = add_column_from_df2_to_df1(squares, fishing_hours, 'c_squar', 'mw_fshn')\n",
    "merged = add_column_from_df2_to_df1(merged, trawling, 'c_squar', 'sbsrfc_sr')\n",
    "merged = add_column_from_df2_to_df1(merged, trawling, 'c_squar', 'srfc_sr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to epsg 3035\n",
    "merged = merged.to_crs(epsg=3035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster saved to /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/fishing_intensity/subsurface_swept_ratio.tif\n",
      "Raster saved to /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/fishing_intensity/surface_swept_ratio.tif\n",
      "Raster saved to /Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/fishing_intensity/fishing_hours.tif\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "\n",
    "def gdf_to_raster(gdf, column, output_path, resolution=None):\n",
    "    \"\"\"\n",
    "    Convert a GeoDataFrame with polygon grid cells to a raster.\n",
    "    \n",
    "    :param gdf: GeoDataFrame with polygon geometries representing a grid\n",
    "    :param column: Name of the column to use for raster values\n",
    "    :param output_path: Path to save the output raster file\n",
    "    :param resolution: Resolution of the output raster. If None, it's calculated from the data\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Ensure the GeoDataFrame is in a projected CRS\n",
    "    if gdf.crs is None or gdf.crs.is_geographic:\n",
    "        raise ValueError(\"GeoDataFrame must be in a projected CRS\")\n",
    "\n",
    "    # Get the extent of the grid\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "    # Calculate resolution if not provided\n",
    "    if resolution is None:\n",
    "        # Assumes square cells and takes the width of the first geometry\n",
    "        resolution = gdf.geometry.iloc[0].bounds[2] - gdf.geometry.iloc[0].bounds[0]\n",
    "\n",
    "    # Calculate raster dimensions\n",
    "    width = int((maxx - minx) / resolution)\n",
    "    height = int((maxy - miny) / resolution)\n",
    "\n",
    "    # Create the transform\n",
    "    transform = from_origin(minx, maxy, resolution, resolution)\n",
    "\n",
    "    # Rasterize the polygons\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[column]))\n",
    "    raster = rasterize(shapes=shapes, out_shape=(height, width), transform=transform, fill=0, all_touched=True)\n",
    "\n",
    "    # Write the raster\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=raster.dtype,\n",
    "        crs=gdf.crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "\n",
    "    print(f\"Raster saved to {output_path}\")\n",
    "\n",
    "gdf_to_raster(merged, 'sbsrfc_sr', '/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/fishing_intensity/subsurface_swept_ratio.tif')\n",
    "gdf_to_raster(merged, 'srfc_sr', '/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/fishing_intensity/surface_swept_ratio.tif')\n",
    "gdf_to_raster(merged, 'mw_fshn', '/Users/loucas/Documents/ORG/github/marine-planning/ecoimpactmapper/fishing_intensity/fishing_hours.tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
